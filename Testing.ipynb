{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1753166171704,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "zW7Yu_N27D4V",
    "outputId": "e2c9cc26-dae3-4b1f-d3dc-0a78f1dac33e"
   },
   "outputs": [],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5InbErDf38LF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,confusion_matrix\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKJQJzRDP4yr"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Seed everything for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # enforce deterministic algorithms (may slow things down)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch 2.x: fully deterministic\n",
    "    if hasattr(torch, \"use_deterministic_algorithms\"):\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "# choose your seed\n",
    "seed_list = [3,5,11,1344,2506]\n",
    "SEED = 3\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1753166192918,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "dQqv_b4U3_vp",
    "outputId": "77f35a17-2ff7-49f5-b98a-e42e478dc49e"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_df_encoded_80_20.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753166210186,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "4AOFu8iMjVTn",
    "outputId": "c04efa26-3c39-417b-8651-aa29f176ac8b"
   },
   "outputs": [],
   "source": [
    "total_abnormal_count = (test_df['label'] == 1).sum() \n",
    "total_normal_count = (test_df['label'] == 0).sum()\n",
    "total_samples = len(test_df)\n",
    "\n",
    "# Print\n",
    "print(\"Total abnormal images:\", total_abnormal_count)\n",
    "print(\"Total normal images:\", total_normal_count)\n",
    "print(\"Total samples:\", total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxA_lSAFTJIx"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to fit most CNNs\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean/std\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "test_dataset = ImageDataset(test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHLmwM8PYNdq"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_by_name(name: str, num_classes=2, device='cuda'):\n",
    "    base_model = models.resnet18\n",
    "    model = base_model(weights=None)\n",
    "    \n",
    "    # --- Modifications ---\n",
    "    in_features = model.fc.in_features\n",
    "    dropout_match = re.search(r'dp\\(([\\d.]+)\\)', name)\n",
    "    dropout_p = float(dropout_match.group(1)) if dropout_match else None\n",
    "    \n",
    "    if \"mod2\" in name:\n",
    "        # Mod 2: Two-layer MLP with dropout\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p if dropout_p is not None else 0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.layer4[:].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    elif \"mod1\" in name:\n",
    "        # Mod 1: Dropout + final layer\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p if dropout_p is not None else 0.5),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "                                )\n",
    "    else:\n",
    "        # Default\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.layer4[:].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    \n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IYzb9SdJH8P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_model_across_folds(model_name_prefix,\n",
    "                                get_model_fn = get_model_by_name,\n",
    "                                test_loader = test_loader,\n",
    "                                device='cuda',\n",
    "                                folds=range(1, 6)):\n",
    "\n",
    "    model_dir = os.path.join(os.getcwd(), model_name_prefix)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    print(\"üîç Testing:\", model_name_prefix)\n",
    "    print(\"üìÇ Saving results in:\", model_dir)\n",
    "\n",
    "    def test_epoch(model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "        inference_times = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(loader, desc='Test', leave=False):\n",
    "                images, labels = images.to(device), labels.to(device).long()\n",
    "                start_time = time.time()\n",
    "                outputs = model(images)\n",
    "                end_time = time.time()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                total_loss += loss.item() * labels.size(0)\n",
    "                total_correct += (preds == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "                inference_times.append(end_time - start_time)\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_acc = total_correct / total_samples\n",
    "        avg_inference_time = np.sum(inference_times) / total_samples  # time per image\n",
    "\n",
    "        return avg_loss, avg_acc, all_labels, all_preds, all_probs, avg_inference_time\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    model_path_final = os.path.join(model_dir, f\"{model_name_prefix}.pth\")\n",
    "\n",
    "    model = get_model_fn(model_name_prefix)\n",
    "    model.load_state_dict(torch.load(model_path_final, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss, test_acc, y_true, y_pred, y_scores, avg_infer_time = test_epoch(\n",
    "        model, test_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    sensitivity = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0.0\n",
    "\n",
    "    results.append({\n",
    "        \"Loss\": test_loss,\n",
    "        \"Accuracy (%)\": accuracy * 100,\n",
    "        \"Precision (%)\": precision * 100,\n",
    "        \"Sensitivity (%)\": sensitivity * 100,\n",
    "        \"Specificity (%)\": specificity * 100,\n",
    "        \"F1 Score (%)\": f1 * 100,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Avg Inference Time (s)\": avg_infer_time\n",
    "    })\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    cm_path = os.path.join(model_dir, f\"{model_name_prefix}_confusion_matrix.png\")\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Normal\", \"Lesion\"], yticklabels=[\"Normal\", \"Lesion\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_path = os.path.join(model_dir, f\"{model_name_prefix}_roc_curve.png\")\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.02, 1.0])\n",
    "    plt.ylim([0.0, 1.02])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(roc_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    csv_path = os.path.join(model_dir, f\"{model_name_prefix}_results.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Evaluation complete. All results saved to: {csv_path}\")\n",
    "    return csv_path, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    \"ResNet18_scratch\",\n",
    "    \"ResNet18_weighted_scratch\",\n",
    "    \"ResNet_18_clf\",\n",
    "    \"ResNet_18_clf_weighted\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = []\n",
    "for model_name in model_list:\n",
    "    path,df = evaluate_model_across_folds(model_name)\n",
    "    csv_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5OT7HPsGvtKPAH4bpQK9F",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1LLELlEvQbOLqf5l69y1Fu2yOTihqRxb9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
