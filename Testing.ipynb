{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1753166171704,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "zW7Yu_N27D4V",
    "outputId": "e2c9cc26-dae3-4b1f-d3dc-0a78f1dac33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5InbErDf38LF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,confusion_matrix\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bKJQJzRDP4yr"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Seed everything for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # enforce deterministic algorithms (may slow things down)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch 2.x: fully deterministic\n",
    "    if hasattr(torch, \"use_deterministic_algorithms\"):\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "# choose your seed\n",
    "seed_list = [3,5,11,1344,2506]\n",
    "SEED = 3\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1753166192918,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "dQqv_b4U3_vp",
    "outputId": "77f35a17-2ff7-49f5-b98a-e42e478dc49e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>611</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2325</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>612</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1216</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2165</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>398</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>668</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2097</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                         image_path  label\n",
       "0      611  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "1     2325  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "2       99  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "3      144  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "4      612  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "..     ...                                                ...    ...\n",
       "489   1216  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "490   2165  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "491    398  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "492    668  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "493   2097  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "\n",
       "[494 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_df_encoded_80_20.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753166210186,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "4AOFu8iMjVTn",
    "outputId": "c04efa26-3c39-417b-8651-aa29f176ac8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total abnormal images: 64\n",
      "Total normal images: 430\n",
      "Total samples: 494\n"
     ]
    }
   ],
   "source": [
    "total_abnormal_count = (test_df['label'] == 1).sum() \n",
    "total_normal_count = (test_df['label'] == 0).sum()\n",
    "total_samples = len(test_df)\n",
    "\n",
    "# Print\n",
    "print(\"Total abnormal images:\", total_abnormal_count)\n",
    "print(\"Total normal images:\", total_normal_count)\n",
    "print(\"Total samples:\", total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NxA_lSAFTJIx"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to fit most CNNs\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean/std\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "test_dataset = ImageDataset(test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHLmwM8PYNdq"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_by_name(name: str, num_classes=2, device='cuda'):\n",
    "    base_model = models.resnet18\n",
    "    model = base_model(weights=None)\n",
    "    \n",
    "    # --- Modifications ---\n",
    "    in_features = model.fc.in_features\n",
    "    dropout_match = re.search(r'dp\\(([\\d.]+)\\)', name)\n",
    "    dropout_p = float(dropout_match.group(1)) if dropout_match else None\n",
    "    \n",
    "    if \"mod2\" in name:\n",
    "        # Mod 2: Two-layer MLP with dropout\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p if dropout_p is not None else 0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.layer4[:].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    elif \"mod1\" in name:\n",
    "        # Mod 1: Dropout + final layer\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p if dropout_p is not None else 0.5),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "                                )\n",
    "    else:\n",
    "        # Default\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.layer4[:].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    \n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1IYzb9SdJH8P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_model_across_folds(model_name_prefix,\n",
    "                                get_model_fn = get_model_by_name,\n",
    "                                test_loader = test_loader,\n",
    "                                device='cuda',\n",
    "                                folds=range(1, 6)):\n",
    "\n",
    "    model_dir = os.path.join(os.getcwd(), model_name_prefix)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    print(\"🔍 Testing:\", model_name_prefix)\n",
    "    print(\"📂 Saving results in:\", model_dir)\n",
    "\n",
    "    def test_epoch(model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "        inference_times = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(loader, desc='Test', leave=False):\n",
    "                images, labels = images.to(device), labels.to(device).long()\n",
    "                start_time = time.time()\n",
    "                outputs = model(images)\n",
    "                end_time = time.time()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                total_loss += loss.item() * labels.size(0)\n",
    "                total_correct += (preds == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "                inference_times.append(end_time - start_time)\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_acc = total_correct / total_samples\n",
    "        avg_inference_time = np.sum(inference_times) / total_samples  # time per image\n",
    "\n",
    "        return avg_loss, avg_acc, all_labels, all_preds, all_probs, avg_inference_time\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    model_path_final = os.path.join(model_dir, f\"{model_name_prefix}.pth\")\n",
    "\n",
    "    model = get_model_fn(model_name_prefix)\n",
    "    model.load_state_dict(torch.load(model_path_final, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss, test_acc, y_true, y_pred, y_scores, avg_infer_time = test_epoch(\n",
    "        model, test_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    sensitivity = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0.0\n",
    "\n",
    "    results.append({\n",
    "        \"Loss\": test_loss,\n",
    "        \"Accuracy (%)\": accuracy * 100,\n",
    "        \"Precision (%)\": precision * 100,\n",
    "        \"Sensitivity (%)\": sensitivity * 100,\n",
    "        \"Specificity (%)\": specificity * 100,\n",
    "        \"F1 Score (%)\": f1 * 100,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Avg Inference Time (s)\": avg_infer_time\n",
    "    })\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    cm_path = os.path.join(model_dir, f\"{model_name_prefix}_confusion_matrix.png\")\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Normal\", \"Lesion\"], yticklabels=[\"Normal\", \"Lesion\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_path = os.path.join(model_dir, f\"{model_name_prefix}_roc_curve.png\")\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.02, 1.0])\n",
    "    plt.ylim([0.0, 1.02])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(roc_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save Results CSV with Mean ± Std\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # avg_row = {\"Fold\": \"Mean ± Std\"}\n",
    "    # for col in df.columns[1:]:\n",
    "    #     if df[col].dtype in [np.float64, float, np.int64]:\n",
    "    #         mean = df[col].mean()\n",
    "    #         std = df[col].std()\n",
    "    #         avg_row[col] = f\"{mean:.4f} ± {std:.4f}\" if \"Time\" in col else f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "    # df = pd.concat([df, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "    csv_path = os.path.join(model_dir, f\"{model_name_prefix}_results.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"\\n✅ Evaluation complete. All results saved to: {csv_path}\")\n",
    "    return csv_path, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list = [\n",
    "    # \"ResNet18_scratch\",\n",
    "    # \"ResNet18_weighted_scratch\",\n",
    "    # \"ResNet18\",\n",
    "    # \"ResNet18_weighted\",\n",
    "    # \"ResNet18_mod1\",\n",
    "    # \"ResNet18_mod1_weighted\",\n",
    "    # \"ResNet18_mod2\",\n",
    "    # \"ResNet18_mod2_weighted\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0.7)\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0.2)\",\n",
    "    # 'ResNet18_mod1_weighted_test'\n",
    "    # \"ResNet18_mod2_weighted_aug\",\n",
    "    # \"ResNet18_mod1_weighted_aug\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0)\",\n",
    "#     \"ResNet50_mod1\",\n",
    "#     \"ResNet50_mod1_weighted\",\n",
    "#     \"ResNet50_mod1_weighted_dp(0.2)\",\n",
    "#     \"ResNet34_mod1\",\n",
    "#     \"ResNet34_mod1_weighted\",\n",
    "#     \"ResNet34_mod1_weighted_dp(0.2)\",\n",
    "    \n",
    "# ]\n",
    "\n",
    "model_list = [\n",
    "    # \"ResNet18_scratch\",\n",
    "    # \"ResNet18_weighted_scratch\",\n",
    "    \"ResNet_18_clf\",\n",
    "    \"ResNet_18_clf_weighted\",\n",
    "    # \"ResNet18_mod1\",\n",
    "    # \"ResNet18_mod1_weighted\",\n",
    "    # \"ResNet18_mod1_test\",\n",
    "    # \"ResNet18_mod1_weighted_test\",\n",
    "    # \"ResNet18_mod2\",\n",
    "    # \"ResNet18_mod2_weighted\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0.2)\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0.4)\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0.6)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing: ResNet_18_clf\n",
      "📂 Saving results in: C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology Dataset Technical Validation\\Model\\Final Code No Val\\ResNet_18_clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Evaluation complete. All results saved to: C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology Dataset Technical Validation\\Model\\Final Code No Val\\ResNet_18_clf\\ResNet_18_clf_results.csv\n",
      "🔍 Testing: ResNet_18_clf_weighted\n",
      "📂 Saving results in: C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology Dataset Technical Validation\\Model\\Final Code No Val\\ResNet_18_clf_weighted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Evaluation complete. All results saved to: C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology Dataset Technical Validation\\Model\\Final Code No Val\\ResNet_18_clf_weighted\\ResNet_18_clf_weighted_results.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = []\n",
    "for model_name in model_list:\n",
    "    path,df = evaluate_model_across_folds(model_name)\n",
    "    csv_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5OT7HPsGvtKPAH4bpQK9F",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1LLELlEvQbOLqf5l69y1Fu2yOTihqRxb9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
