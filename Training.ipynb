{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1753166171704,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "zW7Yu_N27D4V",
    "outputId": "e2c9cc26-dae3-4b1f-d3dc-0a78f1dac33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5InbErDf38LF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,confusion_matrix\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bKJQJzRDP4yr"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Seed everything for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # enforce deterministic algorithms (may slow things down)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch 2.x: fully deterministic\n",
    "    if hasattr(torch, \"use_deterministic_algorithms\"):\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "# choose your seed\n",
    "seed_list = [3,5,11,1344,2506]\n",
    "SEED = 3\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1753166192918,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "dQqv_b4U3_vp",
    "outputId": "77f35a17-2ff7-49f5-b98a-e42e478dc49e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  label\n",
       "0     C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "1     C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "2     C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "3     C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "4     C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "...                                                 ...    ...\n",
       "1970  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "1971  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "1972  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "1973  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "1974  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "\n",
       "[1975 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_df_encoded_80_20.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>611</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2325</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>612</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1216</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2165</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>398</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>668</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2097</td>\n",
       "      <td>C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                         image_path  label\n",
       "0      611  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "1     2325  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "2       99  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "3      144  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "4      612  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "..     ...                                                ...    ...\n",
       "489   1216  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "490   2165  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      1\n",
       "491    398  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "492    668  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "493   2097  C:\\Users\\Anwesh\\Desktop\\Anwesh\\Oralpathology D...      0\n",
       "\n",
       "[494 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_df_encoded_80_20.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753166210186,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "4AOFu8iMjVTn",
    "outputId": "c04efa26-3c39-417b-8651-aa29f176ac8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total abnormal images: 260\n",
      "Total normal images: 1715\n",
      "Total samples: 1975\n",
      "tensor([0.1316, 0.8684], device='cuda:0')\n",
      "Weight Ratio: tensor(6.5962, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "total_abnormal_count = (train_df['label'] == 1).sum() \n",
    "total_normal_count = (train_df['label'] == 0).sum()\n",
    "total_samples = len(train_df)\n",
    "\n",
    "# Print\n",
    "print(\"Total abnormal images:\", total_abnormal_count)\n",
    "print(\"Total normal images:\", total_normal_count)\n",
    "print(\"Total samples:\", total_samples)\n",
    "# Inverse frequency\n",
    "weight_normal = 1 / total_normal_count\n",
    "weight_abnormal = 1 / total_abnormal_count\n",
    "\n",
    "# Normalize\n",
    "total_inv = weight_normal + weight_abnormal\n",
    "weight_normal /= total_inv\n",
    "weight_abnormal /= total_inv\n",
    "\n",
    "# PyTorch tensor\n",
    "class_weights = torch.tensor([weight_normal, weight_abnormal], dtype=torch.float32).to(device)\n",
    "print(class_weights)\n",
    "print('Weight Ratio:',class_weights[1]/class_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NxA_lSAFTJIx"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to fit most CNNs\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean/std\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(train_df, transform=transform)\n",
    "test_dataset = ImageDataset(test_df, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHLmwM8PYNdq"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1IYzb9SdJH8P"
   },
   "outputs": [],
   "source": [
    "# --- Training for one epoch -----------------------------------\n",
    "def train_epoch(model, loader, optimizer,criterion, device):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    \n",
    "    step_times = []\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Train', leave=False):\n",
    "        step_start = time.time()\n",
    "        images, labels = images.to(device), labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).float()                  # [batch, 2] raw logits\n",
    "        loss = criterion(outputs, labels)        # CrossEntropyLoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        step_end = time.time()\n",
    "        step_times.append(step_end - step_start)\n",
    "        \n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc  = total_correct / total_samples\n",
    "\n",
    "    epoch_end = time.time()\n",
    "    epoch_time = epoch_end - epoch_start\n",
    "    \n",
    "    return avg_loss, avg_acc, epoch_time, step_times\n",
    "\n",
    "\n",
    "def validate_epoch(model, loader,criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Val', leave=False):\n",
    "            images, labels = images.to(device), labels.to(device).long()\n",
    "            outputs = model(images).float()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc  = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "    \n",
    "def plot_training_metrics(metrics_path, model_name=None, save_dir=None, dpi=500):\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics from a single training session.\n",
    "\n",
    "    Args:\n",
    "        metrics_path (str): Path to the JSON file containing training metrics.\n",
    "        model_name (str, optional): Name of the model for the plot title. \n",
    "                                    If None, inferred from the filename.\n",
    "        save_dir (str, optional): Directory to save the plot. \n",
    "                                  If None, saved in the same directory as the metrics file.\n",
    "        dpi (int): Dots per inch for the saved plot image.\n",
    "    \"\"\"\n",
    "    # --- Load JSON Metrics ---\n",
    "    with open(metrics_path, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "    train_loss = metrics[\"train_loss\"]\n",
    "    val_loss = metrics[\"val_loss\"]\n",
    "    train_acc = metrics[\"train_acc\"]\n",
    "    val_acc = metrics[\"val_acc\"]\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # --- Set Model Name and Save Directory if not provided ---\n",
    "    if model_name is None:\n",
    "        model_name = os.path.splitext(os.path.basename(metrics_path))[0].replace(\"_metrics\", \"\")\n",
    "    \n",
    "    if save_dir is None:\n",
    "        save_dir = os.path.dirname(metrics_path)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # --- Create Plot --- ðŸ“Š\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    # Plot Loss on the primary y-axis\n",
    "    l1 = ax1.plot(epochs, train_loss, 'o-', label='Train Loss', color='tab:red')\n",
    "    l2 = ax1.plot(epochs, val_loss, 'o--', label='Validation Loss', color='tab:orange')\n",
    "    ax1.set_xlabel('Epochs', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', color='tab:red', fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Create a secondary y-axis for Accuracy\n",
    "    ax2 = ax1.twinx()\n",
    "    l3 = ax2.plot(epochs, train_acc, 's-', label='Train Accuracy', color='tab:blue')\n",
    "    l4 = ax2.plot(epochs, val_acc, 's--', label='Validation Accuracy', color='tab:cyan')\n",
    "    ax2.set_ylabel('Accuracy', color='tab:blue', fontsize=12)\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    # --- Final Touches (Title and Legend) ---\n",
    "    plt.title(f'{model_name}: Training & Validation Metrics', fontsize=16, pad=40)\n",
    "    \n",
    "    # Combine legends from both axes into one\n",
    "    lines = l1 + l2 + l3 + l4\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    fig.legend(\n",
    "        handles=lines,\n",
    "        labels=labels,\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        ncol=4, # Display legend in one row\n",
    "        fontsize='medium',\n",
    "        frameon=True\n",
    "    )\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for the title\n",
    "\n",
    "    # --- Save the Plot ---\n",
    "    save_path = os.path.join(save_dir, f\"{model_name}_training_metrics.png\")\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"âœ… Saved plot: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet50(name: str, num_classes=2, device='cuda'):\n",
    "    base_model = models.resnet50\n",
    "    # --- Pretrained or not ---\n",
    "    if \"scratch\" in name:\n",
    "        model = base_model(weights=None, zero_init_residual=True)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        return model.to(device)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        model = base_model(weights='DEFAULT')\n",
    "    # --- Modifications ---\n",
    "    in_features = model.fc.in_features\n",
    "    dropout_match = re.search(r'dp\\(([\\d.]+)\\)', name)\n",
    "    dropout_p = float(dropout_match.group(1)) if dropout_match else None\n",
    "\n",
    "\n",
    "    \n",
    "    if \"mod2\" in name:\n",
    "        # Mod 2: Two-layer MLP with dropout\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p if dropout_p is not None else 0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.layer4[:].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    elif \"mod1\" in name:\n",
    "        # Mod 1: Dropout + final layer\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p if dropout_p is not None else 0.5),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "                                )\n",
    "        if \"layer4_1\" in name:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.layer4[:].parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.layer4[:].parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    " \n",
    "    else:\n",
    "        # Default\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.layer4[:].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "BATCH_SIZE    = 32\n",
    "EARLY_STOPING_PATIENCE = 20\n",
    "INITIAL_LR = 0.001\n",
    "REDUCE_LR_PATIENCE = 10\n",
    "REDUCE_LR_FACTOR = 0.5\n",
    "CLASS_WEIGHTS = class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model_name_prefix,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = test_loader,\n",
    "    get_model_fn = get_resnet50,\n",
    "    train_epoch_fn = train_epoch,\n",
    "    validate_epoch_fn = validate_epoch,\n",
    "    plot_metrics_fn = plot_training_metrics,\n",
    "    class_weights = CLASS_WEIGHTS,\n",
    "    device='cuda',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    patience=EARLY_STOPING_PATIENCE,\n",
    "    lr=INITIAL_LR,\n",
    "    weight_decay=1e-5,\n",
    "    seed=SEED,\n",
    "    dir_path = os.getcwd(),\n",
    "    metrics_filename=None\n",
    "):\n",
    "\n",
    "    model_dir = os.path.join(dir_path, model_name_prefix)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    all_metrics = []\n",
    "    print('Training',model_name_prefix) \n",
    "\n",
    "    # Model and optimizer\n",
    "    model = get_model_fn(model_name_prefix)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=REDUCE_LR_PATIENCE)\n",
    "    if 'weighted' in model_name_prefix:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(torch.float32))\n",
    "        print('Using Weighted Loss')\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    # History for this fold\n",
    "    hist = {\n",
    "        \"train_loss\": [], \"train_acc\": [],\n",
    "        \"val_loss\": [],   \"val_acc\": [],\n",
    "        \"epoch_time_s\": [], \"avg_step_time_s\": [],\n",
    "        \"lr_history\": []\n",
    "    }\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    model_basename = f\"{model_name_prefix}\"\n",
    "    model_path = os.path.join(model_dir, f\"{model_basename}.pth\")\n",
    "    best_model_path = os.path.join(model_dir, f\"{model_basename}_best.pth\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, epoch_time, step_times = train_epoch_fn(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = validate_epoch_fn(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Record\n",
    "        hist[\"train_loss\"].append(train_loss)\n",
    "        hist[\"train_acc\"].append(train_acc)\n",
    "        hist[\"val_loss\"].append(val_loss)\n",
    "        hist[\"val_acc\"].append(val_acc)\n",
    "        hist[\"epoch_time_s\"].append(epoch_time)\n",
    "        hist[\"avg_step_time_s\"].append(sum(step_times) / len(step_times))\n",
    "        hist[\"lr_history\"].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}: Train Loss={train_loss:.4f}, Acc={train_acc*100:.2f}% | \"\n",
    "              f\"Val Loss={val_loss:.4f}, Acc={val_acc*100:.2f}% | LR={hist['lr_history'][-1]:.6f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            epochs_no_improve = 0\n",
    "            print(\"  â†’ New best model saved\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # Save final model for fold\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    all_metrics.append(hist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Save to file\n",
    "    if metrics_filename is None:\n",
    "        metrics_filename = f\"{model_name_prefix}_training_metrics.json\"\n",
    "    metrics_path = os.path.join(model_dir, metrics_filename)\n",
    "\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(all_metrics[0], f, indent=4)\n",
    "    \n",
    "    print(f\"\\nK-fold cross-validation complete. Metrics written to {metrics_path}.\")\n",
    "    plot_metrics_fn(metrics_path=metrics_path)\n",
    "    model_summary_str = str(summary(model, input_size=(32, 3, 224, 224)))\n",
    "    summary_path = os.path.join(model_dir, f\"{model_name_prefix}_summary.txt\")\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model_summary_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    # \"ResNet18_scratch\",\n",
    "    \"ResNet50_weighted_scratch\",\n",
    "    # \"ResNet34\",\n",
    "    # \"ResNet34_weighted\",\n",
    "    # \"ResNet34_mod1\",\n",
    "    # \"ResNet34_mod1_weighted\",\n",
    "    \"ResNet50_mod2\",\n",
    "    \"ResNet50_mod2_weighted\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0.2)\",\n",
    "    \"ResNet50_mod1_weighted_dp(0.4)\",\n",
    "    # \"ResNet18_mod1_weighted_dp(0.6)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18_mod2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=0.3009, Acc=87.49% | Val Loss=0.2246, Acc=90.69% | LR=0.001000\n",
      "  â†’ New best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02: Train Loss=0.1678, Acc=93.97% | Val Loss=0.3080, Acc=90.08% | LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03: Train Loss=0.1000, Acc=95.95% | Val Loss=0.4525, Acc=89.47% | LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 43/62 [00:16<00:07,  2.64it/s]"
     ]
    }
   ],
   "source": [
    "for model_name in model_list:\n",
    "    run_training(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5OT7HPsGvtKPAH4bpQK9F",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1LLELlEvQbOLqf5l69y1Fu2yOTihqRxb9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
